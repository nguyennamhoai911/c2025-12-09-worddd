// =======================================================================
// MODULE: MAIN CONTROLLER (Entry Point)
// =======================================================================

// --- SYNC LOGIC (Added) ---
// --- SYNC LOGIC (Added) ---
(function checkAndSyncSettings() {
  if (typeof APP_CONFIG === 'undefined') return;
  
  // Check if we are on the Frontend App
  const currentOrigin = window.location.origin;
  const frontendUrl = APP_CONFIG.FRONTEND_URL; // e.g. localhost:3000
  
  // Simple check: if current origin matches frontend url (ignoring protocol mostly relative) or localhost:3000/3005
  if (currentOrigin.includes("localhost:3000") || currentOrigin.includes("localhost:3005") || (frontendUrl && currentOrigin === new URL(frontendUrl).origin)) {
      
      console.log("üü¢ Detected Web App. Checking for config sync...");
      const token = localStorage.getItem('token');
      
      if (token) {
        chrome.storage.sync.set({ authToken: token });
        
        fetch(`${APP_CONFIG.API_URL}/auth/me`, {
             headers: { Authorization: `Bearer ${token}` }
        })
        .then(res => res.json())
        .then(user => {
             if(user.id) {
                 const updates = {};
                   if (user.googleApiKey && user.googleCx) {
                        updates.googleApiKeys = [{ key: user.googleApiKey, cx: user.googleCx }];
                        updates.googleApiKey = user.googleApiKey; 
                        updates.googleSearchEngineId = user.googleCx;
                   }
                   if (user.azureSpeechKey) updates.azureKey = user.azureSpeechKey;
                   if (user.azureSpeechRegion) updates.azureRegion = user.azureSpeechRegion;
                   if (user.geminiApiKey) updates.geminiApiKey = user.geminiApiKey; // Sync Gemini Key
                   
                   if (Object.keys(updates).length > 0) {
                       chrome.storage.sync.set(updates, () => {
                           console.log("‚úÖ Settings synced from Web App:", Object.keys(updates));
                       });
                   }
             }
        })
        .catch(err => console.error("‚ùå Sync Error:", err));
      }
  }
})();

// --- HELPER: Extract Sentence Context (Robust) ---
function extractSentenceContext(selection) {
    if (!selection.anchorNode) return "";
    
    // 1. Get the paragraph or block text
    // Note: anchorNode might be a text node, so use parentElement to get the block
    let parentEl = selection.anchorNode.nodeType === 3 ? selection.anchorNode.parentElement : selection.anchorNode;
    // Attempt to go up to a block-level element if we are in an inline one (like <span> or <b>)
    while (parentEl && window.getComputedStyle(parentEl).display === 'inline') {
        parentEl = parentEl.parentElement;
    }
    if (!parentEl) return selection.toString();

    const fullText = parentEl.innerText || parentEl.textContent;
    const selectedText = selection.toString().trim();
    if (!fullText || !selectedText) return selectedText;

    // 2. Find the approx index of selection in fullText
    // Cannot rely on selection.anchorOffset directly against fullText because DOM structure implies multiple nodes.
    // Instead, we trust that the selected text exists in the paragraph's text.
    // NOTE: If the word appears multiple times, this simple indexOf might fail to pick the *correct* one.
    // For a perfect solution, we need Range-to-Text alignment, but for this level, find the first occurrence 
    // or the one closest to a heuristic is acceptable. 
    // To Improve: We just grab the sentence containing the *first* match.
    
    try {
        if (typeof Intl !== 'undefined' && Intl.Segmenter) {
            const segmenter = new Intl.Segmenter('en', { granularity: 'sentence' });
            const segments = segmenter.segment(fullText);
            
            // Find segment containing the selection
            // Since we don't have exact offset in fullText easily, we search for the segment containing the selected string
            for (const segment of segments) {
                if (segment.segment.includes(selectedText)) {
                    return segment.segment.trim();
                }
            }
        }
    } catch (e) {
        console.warn("Intl.Segmenter failed, fallback to simple split", e);
    }

    // Fallback: Regex Split
    // Split by . ! ? followed by space or end of string
    const sentences = fullText.match(/[^\.!\?]+[\.!\?]+(\s|$)/g) || [fullText];
    const match = sentences.find(s => s.includes(selectedText));
    return match ? match.trim() : selectedText;
}

// --- API: Get AI Translation ---
async function apiGetAiTranslation(text, context) {
    try {
        const storage = await chrome.storage.sync.get(['geminiApiKey', 'authToken']);
        if (!storage.geminiApiKey || !storage.authToken) return null; // Fallback to Google Translate if no key
        
        console.log("ü§ñ Calling Gemini AI...");
        const response = await fetch(`${APP_CONFIG.API_URL}/ai/analyze`, {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json',
                'Authorization': `Bearer ${storage.authToken}`
            },
            body: JSON.stringify({ text, context })
        });
        
        if (response.ok) {
            const data = await response.json();
            return data; // { ipa, meaning, context_translation, part_of_speech }
        }
    } catch (e) {
        console.error("AI Error:", e);
    }
    return null;
}

let mediaRecorder = null;
let audioChunks = [];
let isRecording = false;
let lastRecordedBlob = null;

// 1. Handle Mark Click
async function onMarkClick(btnElement, statusElement, data) {
  if (!data) return;
  btnElement.disabled = true;
  btnElement.style.opacity = "0.7";
  btnElement.style.transform = "scale(0.9)";
  statusElement.innerHTML = '<span style="color:#2196F3">‚è≥ ƒêang l∆∞u...</span>';

  try {
    await apiSaveVocabulary(data);
    btnElement.style.background = "#4CAF50";
    btnElement.style.boxShadow = "0 4px 0 #388E3C";
    statusElement.innerHTML =
      '<span style="color:#4CAF50;">‚úÖ ƒê√£ l∆∞u v√†o s·ªï t·ª´!</span>';
    await saveToHistory(data.text, data);
  } catch (err) {
    btnElement.style.background = "#FF9800";
    if (err.message.includes("Ch∆∞a ƒëƒÉng nh·∫≠p")) {
      statusElement.innerHTML =
        '<span style="color:#F44336">‚ö†Ô∏è Vui l√≤ng ƒëƒÉng nh·∫≠p App!</span>';
    } else {
      statusElement.innerHTML = `<span style="color:#F44336">‚ùå L·ªói: ${err.message}</span>`;
    }
  } finally {
    btnElement.disabled = false;
    btnElement.style.opacity = "1";
    btnElement.style.transform = "scale(1)";
  }
}

// 2. Handle Mic Click
async function handleMicClick(referenceText, btnElement, existingVocab) {
  if (!isRecording) {
    try {
      if (!navigator.mediaDevices) {
        alert("Mic not supported");
        return;
      }
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      mediaRecorder = new MediaRecorder(stream);
      audioChunks = [];
      mediaRecorder.ondataavailable = (e) => audioChunks.push(e.data);
      mediaRecorder.onstop = async () => {
        const resultDiv = document.getElementById("assessment-result");
        if (resultDiv)
          resultDiv.innerHTML =
            '<div style="font-size:12px; color:#ddd; text-align:center;">‚è≥ Processing...</div>';
        try {
          const audioBlob = new Blob(audioChunks, { type: "audio/webm" });
          lastRecordedBlob = audioBlob;
          if (audioBlob.size < 1000) throw new Error("No audio detected.");

          // 1. G·ªçi Azure l·∫•y ƒëi·ªÉm (Code c≈©)
          const result = await assessPronunciation(audioBlob, referenceText);

          // üëá [NEW CODE] T·ª± ƒë·ªông l∆∞u ƒëi·ªÉm v√† th·ªùi gian n·∫øu t·ª´ ƒë√£ t·ªìn t·∫°i
          if (
            existingVocab &&
            existingVocab.id &&
            result.NBest &&
            result.NBest[0]
          ) {
            const score = result.NBest[0].AccuracyScore;

            // G·ªçi API l∆∞u ƒëi·ªÉm ng·∫ßm (kh√¥ng c·∫ßn await ƒë·ªÉ UI ph·∫£n h·ªìi nhanh)
            apiAddScore(existingVocab.id, score).then((success) => {
              if (success) console.log("‚úÖ Score & Time synced to DB!");
            });

            // C·∫≠p nh·∫≠t l·∫°i UI Badge ƒëi·ªÉm ngay l·∫≠p t·ª©c (Optional - Visual feedback)
            // B·∫°n c√≥ th·ªÉ update l·∫°i bi·∫øn existingVocab.pronunciationScores local ·ªü ƒë√¢y n·∫øu mu·ªën
          }
          // üëÜ [END NEW CODE]

          renderAssessmentResult(result, resultDiv, referenceText, {
            playUserAudio: () => {
              const u = URL.createObjectURL(lastRecordedBlob);
              new Audio(u).play();
            },
            speakEdge: speakWithEdgeTTS,
          });
        } catch (err) {
          if (resultDiv)
            resultDiv.innerHTML = `<div style="color:#ff5252; text-align:center;">‚ùå ${err.message}</div>`;
        } finally {
          stream.getTracks().forEach((t) => t.stop());
        }
      };
      mediaRecorder.start();
      isRecording = true;
      btnElement.classList.add("recording");
    } catch (err) {
      alert("Mic Error: " + err.message);
    }
  } else {
    if (mediaRecorder) mediaRecorder.stop();
    isRecording = false;
    btnElement.classList.remove("recording");
  }
}

// 3. Main Event Listener
document.addEventListener("keydown", async (e) => {
  if (e.key === "Shift") {
    const selection = window.getSelection();
    const selectedText = selection.toString().trim();

    if (selectedText) {
      let contextText = extractSentenceContext(selection); // Use new helper
      if (contextText.length > 200) contextText = "..." + contextText.substring(0, 200) + "..."; // Safeguard

      // 1. Setup Popup Coordinates & Create Shell
      const rect = selection.getRangeAt(0).getBoundingClientRect();
      const popup = createPopup(); // Defined in lookup-ui.js
      isPopupOpen = true;

      const topPos =
        rect.top + window.scrollY - 450 < window.scrollY
          ? rect.bottom + window.scrollY + 10
          : rect.top + window.scrollY - 450;
      const leftPos =
        rect.left + window.scrollX + 350 > window.innerWidth
          ? window.innerWidth - 360
          : rect.left + window.scrollX;

      popup.style.top = `${topPos}px`;
      popup.style.left = `${leftPos}px`;
      
      // Mutable Data Object (Filled progressively)
      const currentData = {
          text: selectedText,
          contextText: contextText,
          isAi: true,
          existing: null
      };

      // Callbacks
      const safeToggleSound = typeof toggleSoundState !== 'undefined' ? toggleSoundState : () => {};
      const callbacks = {
          closePopup,
          toggleSound: safeToggleSound,
          speakEdge: speakWithEdgeTTS,
          handleMic: (referenceText, btnElement) => handleMicClick(referenceText, btnElement, currentData.existing),
          handleMark: (btn, status) => onMarkClick(btn, status, currentData)
      };

      // 2. ‚ö° RENDER INITIAL SHELL (Wait for nothing)
      if (typeof renderInitialPopup === 'function') {
          renderInitialPopup(selectedText, callbacks);
      } else {
          // Fallback if UI script outdated
          popup.innerHTML = '<div class="tts-content"><div class="tts-loading">‚ú® ƒêang x·ª≠ l√Ω...</div></div>';
          popup.style.display = "block";
      }

      // Play Audio immediately
      speakWithEdgeTTS(selectedText);
      
      // 3. üöÄ PARALLEL EXECUTION: Start Tasks independently
      
      // TASK A: AI Translation
      apiGetAiTranslation(selectedText, contextText)
          .then(aiData => {
              if (aiData) {
                  // Update Data Object
                  currentData.translation = {
                      wordMeaning: aiData.meaning,
                      contextMeaning: aiData.context_translation,
                      commonMeanings: aiData.common_meanings || ""
                  };
                  currentData.phonetics = { us: aiData.ipa, uk: null };
                  currentData.partOfSpeech = aiData.part_of_speech;
                  currentData.contextHighlight = aiData.context_highlight;

                   // fetch images in background
                  getImages(selectedText);

                  // Update UI
                  if (typeof updatePopupAiData === 'function') {
                      updatePopupAiData(currentData);
                  }
              } else {
                  // AI Failed UI
                   const contentArea = document.getElementById("content-area");
                   if(contentArea) contentArea.innerHTML = `<div style="color:#d32f2f; padding:10px;">‚ö†Ô∏è AI Analysis failed. Please check your API Key.</div>`;
              }
          })
          .catch(err => {
              console.error("AI Task Error:", err);
               const contentArea = document.getElementById("content-area");
               if(contentArea) contentArea.innerHTML = `<div style="color:#d32f2f; padding:10px;">‚ùå Error: ${err.message}</div>`;
          });

      // TASK B: DB Check (Independent)
      apiCheckVocabulary(selectedText)
          .then(existingVocab => {
              currentData.existing = existingVocab;
              // Update UI
              if (typeof updatePopupDbData === 'function') {
                  updatePopupDbData(existingVocab);
              }
          })
          .catch(err => {
              // Ignore DB errors (just assume not starred)
          });

    } else if (isPopupOpen) {
      closePopup();
    }
  } else if (e.key === "Escape" && isPopupOpen) {
    closePopup();
  }
});

// 4. Flashcard Listener
// 4. Flashcard Listener
chrome.runtime.onMessage.addListener(async (request, sender, sendResponse) => {
  if (request.action === "SHOW_FLASHCARD") {
    console.log("üì© Received SHOW_FLASHCARD message");

    try {
      // Step 1: L·∫•y danh s√°ch t·ª´ Starred t·ª´ Backend
      const list = await apiGetStarredVocabulary();

      if (list && list.length > 0) {
        // Step 2: L·∫•y index hi·ªán t·∫°i t·ª´ Storage (Logic Xoay V√≤ng)
        const storageData = await chrome.storage.local.get([
          "flashcardCurrentIndex",
        ]);
        let currentIndex = storageData.flashcardCurrentIndex || 0;

        // Validate: N·∫øu index v∆∞·ª£t qu√° ƒë·ªô d√†i list (do x√≥a b·ªõt t·ª´), reset v·ªÅ 0
        if (currentIndex >= list.length) {
          currentIndex = 0;
        }

        // Pick t·ª´ theo th·ª© t·ª±
        const selectedItem = list[currentIndex];
        console.log(
          `üîÑ Rotational Pick [${currentIndex + 1}/${list.length}]:`,
          selectedItem.word
        );

        // Step 3: T√≠nh to√°n Index ti·∫øp theo v√† L∆∞u l·∫°i ngay
        const nextIndex = (currentIndex + 1) % list.length; // Quay v√≤ng v·ªÅ 0 n·∫øu h·∫øt list
        await chrome.storage.local.set({ flashcardCurrentIndex: nextIndex });

        // Step 4: Map Data
        const flashcardItem = {
          word: selectedItem.word,
          data: {
            translation: selectedItem.meaning || "No definition",
            pronunciation: selectedItem.pronunciation || "",
            partOfSpeech: selectedItem.partOfSpeech || "",
            images: [],
          },
        };

        // Step 5: Show UI (Gi·ªØ nguy√™n logic c≈©)
        showFlashcard(flashcardItem, {
          speakEdge: speakWithEdgeTTS,

          // Mic Logic
          onMic: () => {
            if (window.NativeUI) {
              window.NativeUI.renderAssessmentModal(
                {
                  ...selectedItem,
                  pronunciation: selectedItem.pronunciation || "",
                },
                {
                  onSpeak: (t) => speakWithEdgeTTS(t),
                  onRecord: async (onSuccess, onError) => {
                    try {
                      const stream = await navigator.mediaDevices.getUserMedia({
                        audio: true,
                      });
                      const mediaRecorder = new MediaRecorder(stream);
                      const chunks = [];
                      mediaRecorder.ondataavailable = (e) =>
                        chunks.push(e.data);
                      mediaRecorder.onstop = async () => {
                        const blob = new Blob(chunks, { type: "audio/webm" });
                        window.lastRecordedBlob = blob;
                        try {
                          const result = await assessPronunciation(
                            blob,
                            selectedItem.word
                          );
                          if (
                            selectedItem.id &&
                            result.NBest &&
                            result.NBest[0]
                          ) {
                            apiAddScore(
                              selectedItem.id,
                              result.NBest[0].AccuracyScore
                            );
                          }
                          if (result.NBest) onSuccess(result.NBest[0]);
                          else onError("No result");
                        } catch (err) {
                          onError(err.message);
                        }
                        stream.getTracks().forEach((t) => t.stop());
                      };
                      mediaRecorder.start();
                      window.currentRecorder = mediaRecorder;
                    } catch (e) {
                      onError("Mic Error: " + e.message);
                    }
                  },
                  onStop: () => {
                    if (window.currentRecorder) window.currentRecorder.stop();
                  },
                  onPlayback: () => {
                    if (window.lastRecordedBlob) {
                      const url = URL.createObjectURL(window.lastRecordedBlob);
                      new Audio(url).play();
                    }
                  },
                }
              );
            }
          },

          // Edit Logic
          onEdit: () => {
            if (window.NativeUI) {
              window.NativeUI.renderFormModal(
                { ...selectedItem, isEditMode: true },
                {
                  onAutoFill: () => null,
                  onSave: async (d) => {
                    await apiUpdateVocabulary(d.id, d);
                  },
                }
              );
            }
          },
        });
      } else {
        console.log(
          "‚ö†Ô∏è No starred words found. Please star some words in App."
        );
      }
    } catch (e) {
      console.error("üî• Flashcard Error:", e);
    }
  }
});
